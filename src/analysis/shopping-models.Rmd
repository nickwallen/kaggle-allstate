```{r, include=FALSE}

library (data.table)
library (ggplot2)
library (reshape2)
library (lubridate)
library (stringr)
library (caret)
library (gridExtra)

source ("../R/fetch.R")
source ("../R/features.R")
source ("../R/shopping-models.R")
source ("../R/alpha-shopping-model.R")
source ("../R/naive-shopping-model.R")
source ("../R/popular-shopping-model.R")
source ("../R/score.R")
source ("../R/utils.R")
source ("../R/cache.R")

# set global options for all code chunks
opts_chunk$set(fig.width=12, fig.height=8, tidy=T)
```

Modeling of Customer Shopping History
========================================================
The customer demographic data and the customer shopping history are completely different types of data.  We are going to model each of these independently.  The final prediction will be an ensemble between the two.  The initial challenge for the shopping history data is in flattening a customer's shopping history into one single record that can be used to train and predict the customer's final purchase plan.  

### Preprocessing

The input shopping data looks like the following.

| customer.id | shopping.pnt | record.type | day.of.week | time.of.day.hours | option.a | option.b | ... |
| ----------- | ------------ | ----------- | ----------- | ----------------- | -------- | -------- | ----|                                                 
| 123456789   | 1            | shopping    | Mon         | 2.25              | 0        | 1        |     |
| 123456789   | 2            | shopping    | Mon         | 3.25              | 0        | 1        |     |
| 123456789   | 3            | shopping    | Mon         | 3.50              | 1        | 2        |     |
| 123456789   | 4            | shopping    | Mon         | 4.00              | 1        | 2        |     |
| 123456789   | 5            | shopping    | Mon         | 5.00              | 0        | 2        |     |
| 123456789   | 6            | purchase    | Mon         | 6.26              | 0        | 2        |     |
| 000000001   | 1            | shopping    | Tue         | 2.25              | 0        | 1        |     |
| 000000001   | 2            | shopping    | Tue         | 3.25              | 0        | 1        |     |
| 000000001   | 3            | purchase    | Tue         | 3.50              | 1        | 2        |     |

The input data could be transformed as follows for training and prediction.

| customer.id | option.a.0 | option.a.1 | option.a.2 | option.b.0 | option.b.1 | option.a | option.b | ... | 
| ----------- | ---------- | ---------- | ---------- | ---------- | ---------- | -------- | -------- | --- |
| 123456789   | 3          | 2          | 0          | 2          | 2          | 0        | 2        |     |
| 000000001   | 2          | 0          | 0          | 0          | 2          | 1        | 2        |     |

The definition for each of these fields is as follows.

| Field         | Definition 
| ------------- | ---------- 
| *customer.id* | The customer's unique ID.  Each customer will have one record in training data.       
| *option.a.0*  | The total number of times the customer shopped for choice 0 of option A in the shopping history.
| *option.a.1*  | ...
| *option.a.2*  | ...
| *option.b.0*  | The total number of times the customer shopped for choice 0 of option A in the shopping history.
| *option.b.1*  | ...
| *option.a*    | The outcome for option a that is being predicted.  The value for this field comes from the purchase record.
| *option.b*    | ...

### Popular Model

Let's first look at a popular model.  The popular model simply chooses the option that has been shopped for by most
customers.  If a customer looks at the same option multiple times, then the option receives multiple votes.

```{r popular.model, results='hide'}

# split the data into representative test/train sets
data <- fetch()
add.plan (data)
train.index <- createDataPartition (data$plan, p = 0.8, list = F)[,1]

# create a train and test set
train <- data [  train.index ]
test  <- data [ -train.index ]

# preprocess the train and test sets
train <- train [record.type == "purchase"]
test  <- test  [record.type == "purchase"]

# train on the purchase records only
models <- train.popular.model (train )

# make predictions with the popular model
test [, options.hat() := predict.popular.model (models, .SD), with = F]

```

How did the popular model perform?

```{r popular.model.score}

# score the results
accuracy.score (test)
partial.accuracy.score (test)
```

Take a closer look using a confusion matrix for each option.

```{r popular.model.confusion.matrix}

with (test, confusionMatrix(option.a.hat, option.a))
with (test, confusionMatrix(option.b.hat, option.b))
with (test, confusionMatrix(option.c.hat, option.c))
with (test, confusionMatrix(option.d.hat, option.d))
with (test, confusionMatrix(option.e.hat, option.e))
with (test, confusionMatrix(option.f.hat, option.f))
with (test, confusionMatrix(option.g.hat, option.g))
```

### Alpha Model - Shopping History

This model uses a classification tree to predict the final purchased option based on the number of times that customer has shopped for a particular valid option.  In addition, each option (a-g) is modeled separately.

```{r shopping.counts.model}

# fetch the competition training data set and transform it for training
data <- fetch()
data.shopping <- extract.shopping.history (data, sum)
data.shopping <- extract.purchase.history (data, data.shopping)

# split the data into representative test/train sets
add.plan (data.shopping)
train.index <- createDataPartition (data.shopping$plan, p = 0.8, list = F)[,1]

# create a train and test set
train <- data.shopping [  train.index ]
test  <- data.shopping [ -train.index ]


models <- train.alpha.model (train)

```

How did the parameter tuning go?

```{r shopping.counts.tuning}

# create tuning plots for each model
plots <- lapply (models, function (m) ggplot (m))

# draw each of the plots on the same canvas
do.call(grid.arrange,  plots)

```

Which predictors are most important?  The results seem to show that a customer shopping for a particular option is indicative of what they will eventually purchase.  In addition it does not seem like the selection across option types has any significant impact.  For example, the selection of option A.1 does not impact E.2 or anything like that.

```{r shopping.counts.importance.plots}

# create variable importance plots for each model
plots <- lapply (models, function (m) plot (varImp (m, scale = F), top = 10))

# draw each of the plots on the same canvas
do.call(grid.arrange,  plots)

```

Make predictions with the various models.

```{r shopping.counts.predictions, results='hide'}

for (option.hat in names (models)) {

  # make a prediction for each option
  model <- models[[option.hat]]
  test [, option.hat := predict (model, .SD), 
                 .SDcols = 2:23, with = FALSE ]
}
```

How accurate are the predictions?

```{r shopping.counts.accuracy}

# score the results
accuracy.score (test)
partial.accuracy.score (test)

```

Take a closer look using a confusion matrix for each option.

```{r shopping.counts.confusion.matrix}

with (test, confusionMatrix(option.a.hat, option.a))
with (test, confusionMatrix(option.b.hat, option.b))
with (test, confusionMatrix(option.c.hat, option.c))
with (test, confusionMatrix(option.d.hat, option.d))
with (test, confusionMatrix(option.e.hat, option.e))
with (test, confusionMatrix(option.f.hat, option.f))
with (test, confusionMatrix(option.g.hat, option.g))
```

Run the models on the actual competition test data to create a submission.

```{r}
champion.shopping.model (verbose = TRUE)
```

### Customers Who Purchase Unquoted Policies

Could we determine which customers are likely to purchase policies for which they never received a quote?  These are customers who purchase options different from their last shopping point.  For all customers who are likely to purchase something without a previous quote, then predict using the data.  For all other customers, just choose the latest shopping point.  This might show a marked improvement since the naive model seems difficult to beat by simply making predictions for every customer.

Could also use the 'shopping.pt' value of the latest quote which matches the purchase.  Then '0' might indicate that no quote matches the purchase.

```{r}
data <- fetch ()
add.last.quote (data)
add.plan (data)
```

What is the distribution of 'last quote'?  Most often there has never been a quote for exactly what was purchased.

```{r}
ggplot (data, aes (last.quote)) + geom_histogram()
```

Is it more likely for the customer to purchase something they were quoted for?  Most of the time customers purchase a policy for which they were previously quoted.

```{r}
ggplot (data, aes (last.quote == 0)) + geom_histogram()
table (data$last.quote == 0)

with (data, table (plan, last.quote == 0))
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.a)
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.b)
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.c)
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.d)
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.e)
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.f)
ggplot (data, aes (last.quote == 0)) + geom_histogram() + facet_wrap( ~ option.g)
```

Can we predict which customers will buy unquoted policies?  'Unquoted Purchase'?

```{r}

# add a yes/no indicator instead of using the raw count from last.quote
data [, unquoted.purchase := (last.quote == 0) ]

# split the data into representative test/train sets
train.index <- createDataPartition (data$unquoted.purchase, p = 0.8, list = F)[,1]

# create a train and test set
keep <- c(options(), "unquoted.purchase")
train <- data [  train.index, keep, with = F ]
test  <- data [ -train.index, keep, with = F ]

# defines how the parameter tuning will occur
control <- trainControl (method = "cv", number = 2)

# which model parameters will be tuned?
tune.grid <- expand.grid (
  n.trees           = c(50, 100, 200), 
  shrinkage         = 0.1,
  interaction.depth = c(1, 5, 9))

# tune/train a separate model for each option
model <- train (
  form      = as.factor (unquoted.purchase) ~ . ,
  data      = train,
  method    = "gbm", 
  trControl = control,
  tuneGrid  = tune.grid,
  verbose   = TRUE 
)

# make a prediction 
test [, unquoted.purchase.hat := predict (model, newdata = .SD) ]
with (test, confusionMatrix (unquoted.purchase, unquoted.purchase.hat)) 

```

### TODO - Ensembles 

The naive model is relatively effective for the competition. Even the best competitors are beating it by only a few points. This indicates that in most cases customers purchase plans for which they have previously (and most recently) received a quote. For these customers, the naive model might be the best model.

Alternatively, there are other customers who will choose to purchase an unquoted plan. For these customers an alternative shopping or customer-based model should be used to improve accuracy.  This could be accomplished by ensembling the naive model with another model and have the ensemble model decide when each model should be applied.

Steps
  - create predictions with alpha model
  - create prediction with naive model
  - merge the data so that there is one row for each customer that includes all of the customer's attributes, the options predicted by each model, and the actual option values
  - predict each of the following:

```
  option.a ~ age + car.age + risk + ... + alpha.option.a.hat + naive.option.a.hat
  option.b ~ age + car.age + risk + ... + alpha.option.b.hat + naive.option.b.hat
```

```{r}

# make predictions with the naive model
naive.models <- train.naive.model (data)
naive.predictions <- predict.naive.model (naive.models)

# make predictions with the alpha model
# TODO - need a function to get just the predictoins for the alpha model

```

### Recency of Shopping Points

Perhaps a difference value for each of the 'option.x.n' fields could be used.  Perhaps ones that applies a greater weight to more recent shopping history or the mean instead of the sum.

There does appear to be some improvement when the recency of shopping history is taken into account.  It is is not a major improvement, but it helps.  Compare the following.

```{r}
champion.shopping.model (mean)
champion.shopping.model (weighted.sum.most.recent)
```


### TODO 

This takes care of the option elements of the shopping history, but how should the additional date-related 'day.of.week' and 'time.of.day.hours' fields be leveraged in the analysis.






